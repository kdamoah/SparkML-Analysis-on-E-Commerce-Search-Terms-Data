{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "        <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"300\" alt=\"Skills Network Logo\">\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse search terms on the e-commerce web server\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In this assignment you will download the search term data set for the e-commerce web server and run analytic queries on it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting py4j==0.10.9.5\n",
      "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845498 sha256=12e5a9fe3191bf3f2c854303f5147543230445374a1ab1704898cec66727f46f\n",
      "  Stored in directory: /home/jupyterlab/.cache/pip/wheels/91/aa/66/700b503fd714b56462975ab7bf33485ec26677c3c990e67e9a\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    }
   ],
   "source": [
    "# Installing spark\n",
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.regression import LinearRegressionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/11/21 18:34:01 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# Start spark session\n",
    "\n",
    "# Creating a spark context class\n",
    "sc = SparkContext()\n",
    "\n",
    "# Creating a spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark Dataframes and SparkML Model\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>searchterm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>mobile 6 inch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>mobile latest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>tablet wifi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>laptop 14 inch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>mobile 5g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day  month  year      searchterm\n",
       "0   12     11  2021   mobile 6 inch\n",
       "1   12     11  2021   mobile latest\n",
       "2   12     11  2021     tablet wifi\n",
       "3   12     11  2021  laptop 14 inch\n",
       "4   12     11  2021       mobile 5g"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading csv file from the url using pandas\n",
    "# https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/searchterms.csv\n",
    "\n",
    "searchterms = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/searchterms.csv\")\n",
    "\n",
    "# Checking the first 5 rows of the dataframe\n",
    "searchterms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pandas dataframe into a spark dataframe\n",
    "sdf = spark.createDataFrame(searchterms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:=======>                                                   (1 + 7) / 8]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Checking the number of rows and columns in the spark dataframe\n",
    "print((sdf.count(), len(sdf.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+--------------+\n",
      "|day|month|year|    searchterm|\n",
      "+---+-----+----+--------------+\n",
      "| 12|   11|2021| mobile 6 inch|\n",
      "| 12|   11|2021| mobile latest|\n",
      "| 12|   11|2021|   tablet wifi|\n",
      "| 12|   11|2021|laptop 14 inch|\n",
      "| 12|   11|2021|     mobile 5g|\n",
      "+---+-----+----+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking the first 5 rows of the spark dataframe\n",
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('day', 'bigint'),\n",
       " ('month', 'bigint'),\n",
       " ('year', 'bigint'),\n",
       " ('searchterm', 'string')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the datatypes of the each column in the dataframe\n",
    "sdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "499"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the number of times the term `gaming laptop` is searched\n",
    "\n",
    "sdf.filter(sdf['searchterm'] == 'gaming laptop').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===============================================>      (176 + 15) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|   searchterm|count|\n",
      "+-------------+-----+\n",
      "|mobile 6 inch| 2312|\n",
      "|    mobile 5g| 2301|\n",
      "|mobile latest| 1327|\n",
      "|       laptop|  935|\n",
      "|  tablet wifi|  896|\n",
      "+-------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# 5 most frequently used search terms\n",
    "sdf.groupby('searchterm') \\\n",
    ".count() \\\n",
    ".sort(desc('count')) \\\n",
    ".show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-21 18:34:27--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/model.tar.gz\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1490 (1.5K) [application/x-tar]\n",
      "Saving to: ‘model.tar.gz’\n",
      "\n",
      "model.tar.gz        100%[===================>]   1.46K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-11-21 18:34:28 (9.69 MB/s) - ‘model.tar.gz’ saved [1490/1490]\n",
      "\n",
      "sales_prediction.model/\n",
      "sales_prediction.model/metadata/\n",
      "sales_prediction.model/metadata/part-00000\n",
      "sales_prediction.model/metadata/.part-00000.crc\n",
      "sales_prediction.model/metadata/_SUCCESS\n",
      "sales_prediction.model/metadata/._SUCCESS.crc\n",
      "sales_prediction.model/data/\n",
      "sales_prediction.model/data/part-00000-1db9fe2f-4d93-4b1f-966b-3b09e72d664e-c000.snappy.parquet\n",
      "sales_prediction.model/data/_SUCCESS\n",
      "sales_prediction.model/data/.part-00000-1db9fe2f-4d93-4b1f-966b-3b09e72d664e-c000.snappy.parquet.crc\n",
      "sales_prediction.model/data/._SUCCESS.crc\n"
     ]
    }
   ],
   "source": [
    "# Downloading and load a pretrained sales forecasting model from the url\n",
    "# https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/model.tar.gz\n",
    "\n",
    "'''\n",
    "The sales forecasting model is an already pretrained linear regression model. It infers that the input is year and and the output is sales.\n",
    "Hence, the predictor variable is year and the response variable is sales. \n",
    "To understand how the model is built, please refer to the file `part-00000` in the metadata folder of the sales_prediction.model folder.\n",
    "(Path: sales_prediction.model > metadata > part-0000.\n",
    "'''\n",
    "\n",
    "# Model download\n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DB0321EN-SkillsNetwork/Bigdata%20and%20Spark/model.tar.gz\n",
    "\n",
    "# Extracting the content of the zip file\n",
    "!tar -xvf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Loading the extracted contenet from the zip file (this will be the sales_prediction.model)\n",
    "\n",
    "# Loading model\n",
    "model = LinearRegressionModel.load('sales_prediction.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The intercept of the model is -13019.989140447298\n",
      "The coefficient of the model is 6.522567861288859\n"
     ]
    }
   ],
   "source": [
    "# Checking the intercept and coefficient of the linear regression model\n",
    "print('The intercept of the model is', model.intercept)\n",
    "print('The coefficient of the model is', model.coefficients[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function predicts the sales for a chosen year\n",
    "def predict(year):\n",
    "    # A linear regression equation for prediction\n",
    "    prediction = model.intercept + (model.coefficients[0] * year)\n",
    "    # Returns the predicted value\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sales prediction for 2023 is 175.17\n"
     ]
    }
   ],
   "source": [
    "# Prediction of sales for the year 2023\n",
    "print(f'The sales prediction for 2023 is {predict(2023):.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
